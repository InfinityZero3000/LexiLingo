# LexiLingo AI Core System

Complete AI pipeline implementation following the architecture in `/docs/architecture.md`.

## ğŸ“ Structure

```
lib/core/ai/
â”œâ”€â”€ models/               # Data models
â”‚   â”œâ”€â”€ ai_task.dart     # Task types, complexity, learner levels
â”‚   â””â”€â”€ ai_response.dart # Response formats, analysis results
â”œâ”€â”€ context/             # Context management
â”‚   â””â”€â”€ context_manager.dart  # Conversation history, learner profile
â”œâ”€â”€ stt/                 # Speech-to-Text
â”‚   â””â”€â”€ stt_service.dart      # Faster-Whisper v3 interface
â”œâ”€â”€ tts/                 # Text-to-Speech
â”‚   â””â”€â”€ tts_service.dart      # Piper VITS interface
â”œâ”€â”€ pronunciation/       # Pronunciation analysis
â”‚   â””â”€â”€ pronunciation_service.dart  # HuBERT interface
â””â”€â”€ orchestrator/        # Core coordinator
    â””â”€â”€ ai_orchestrator.dart   # Main AI pipeline
```

## ğŸ¯ Core Components

### 1. AI Orchestrator

Central coordinator managing the entire AI pipeline.

**Key Features:**
- Task analysis and planning
- Resource allocation (lazy loading)
- Parallel execution (Grammar + Pronunciation)
- Error handling with graceful degradation
- State management

**Architecture Phases:**
1. **Task Analysis** - Detect task type, complexity, learner level
2. **Resource Allocation** - Load required models on-demand
3. **Execution Coordination** - Sequential + parallel processing
4. **Error Handling** - Fallback strategies
5. **State Management** - Track loaded models, metrics

### 2. Context Manager

Manages conversation history and learner profile.

**Features:**
- Sliding window history (last 5 turns)
- Learner profile caching (Redis - TODO)
- Context embedding (all-MiniLM-L6-v2 - TODO)
- Knowledge graph integration (TODO)

### 3. STT Service (Speech-to-Text)

Interface for Faster-Whisper v3 model.

**Specs:**
- Model: openai/whisper-small (244MB)
- Latency: 50-100ms
- WER: <10% (ESL)
- Features: VAD, streaming, word timestamps

### 4. TTS Service (Text-to-Speech)

Interface for Piper VITS model.

**Specs:**
- Model: en_US-lessac-medium
- Size: 30-60MB
- Latency: 100-300ms
- Features: Natural prosody, offline capable, caching

### 5. Pronunciation Service

Interface for HuBERT-large model.

**Specs:**
- Model: hubert-large-ls960
- Size: 960MB
- Latency: 100-200ms
- Features: Phoneme recognition, forced alignment

## ğŸš€ Usage

### Basic Text Processing

```dart
import 'package:lexilingo_app/core/ai/orchestrator/ai_orchestrator.dart';
import 'package:lexilingo_app/core/ai/context/context_manager.dart';
import 'package:lexilingo_app/core/ai/stt/stt_service.dart';
import 'package:lexilingo_app/core/ai/tts/tts_service.dart';
import 'package:lexilingo_app/core/ai/pronunciation/pronunciation_service.dart';

// Initialize
final contextManager = ContextManager();
final orchestrator = AIOrchestrator(
  contextManager: contextManager,
  sttService: MockSTTService(),      // Replace with real implementation
  ttsService: MockTTSService(),      // Replace with real implementation
  pronunciationService: MockPronunciationService(), // Replace with real
);

await orchestrator.initialize();

// Set learner profile
contextManager.setLearnerProfile(LearnerProfile(
  userId: 'user123',
  level: LearnerLevel.a2,
  commonErrors: ['past_tense', 'articles'],
  totalSessions: 10,
));

// Process text input
final response = await orchestrator.processText(
  userText: 'I am go to the kitchen for coffee',
);

print('Analysis: ${response.analysis}');
print('Response (EN): ${response.responseEn}');
print('Response (VI): ${response.responseVi}');
print('Confidence: ${response.confidence}');
print('Latency: ${response.latencyMs}ms');
```

### Audio Processing (with Pronunciation)

```dart
// Assume we have audio bytes from microphone
final audioBytes = Uint8List.fromList([...]); // Your audio data

// Process audio (includes STT + Pronunciation analysis)
final response = await orchestrator.processAudio(
  audioBytes: audioBytes,
);

// Check pronunciation
if (response.analysis.pronunciation != null) {
  final pronResult = response.analysis.pronunciation!;
  print('Pronunciation accuracy: ${pronResult.accuracy}');
  print('Errors: ${pronResult.errors}');
  print('Prosody: ${pronResult.prosodyScore}');
}

// Synthesize response to audio
final responseAudio = await orchestrator.synthesizeResponse(
  response.responseEn,
);

// Play responseAudio...
```

## ğŸ”„ Architecture Flow

### Text Input Flow

```
User Text
    â†“
Task Analysis â†’ Determine tasks, complexity, learner level
    â†“
Context Retrieval â†’ Get conversation history, learner profile
    â†“
Grammar Analysis (Qwen) â†’ Fluency, vocabulary, errors
    â†“
Vietnamese Explanation? â†’ If A2 or low confidence
    â†“
Tutor Response â†’ Generate feedback
    â†“
Response Aggregation â†’ Final AIResponse
```

### Audio Input Flow

```
Audio Bytes
    â†“
STT (Faster-Whisper) â†’ Transcribe to text
    â†“
Task Analysis
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Grammar        â”‚ Pronunciation  â”‚ (Parallel)
â”‚ Analysis       â”‚ Analysis       â”‚
â”‚ (Qwen)         â”‚ (HuBERT)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Wait for all tasks
    â†“
Vietnamese Explanation? â†’ If needed
    â†“
Tutor Response
    â†“
Response Aggregation
```

## ğŸ“Š Task Types

- **Grammar** - Correction and analysis
- **Fluency** - Natural flow assessment
- **Vocabulary** - Level detection (A2/B1/B2)
- **Dialogue** - Conversation practice
- **Pronunciation** - Phoneme accuracy (audio only)
- **Vietnamese Explanation** - For A2 learners

## ğŸ“ Learner Levels

- **A2** - Elementary (needs more hand-holding, Vietnamese)
- **B1** - Intermediate (gentle corrections)
- **B2** - Upper-Intermediate (minimal assistance)

## ğŸ›¡ï¸ Error Handling

The orchestrator implements graceful degradation:

**Level 1: Component Failure**
- If Qwen fails â†’ Use cached response or rule-based
- If HuBERT fails â†’ Skip pronunciation
- If LLaMA3-VI fails â†’ Use English only

**Level 2: Timeout Management**
- Task timeout: 500ms per component
- Total timeout: 2s for full pipeline
- If timeout â†’ Return partial results

**Level 3: Resource Exhaustion**
- GPU OOM â†’ Offload to CPU
- CPU overload â†’ Queue request, return cached

## ğŸ“ˆ Performance Metrics

Track and monitor:
- Latency per component
- Resource usage (GPU%, RAM)
- Error rates by component
- Cache hit rates

```dart
// Get metrics
final metrics = orchestrator.performanceMetrics;
print(metrics);

// Check loaded models
final loaded = orchestrator.loadedModels;
print('Loaded: $loaded');
```

## ğŸ”§ TODO: Integration Checklist

- [ ] Replace MockSTTService with real Faster-Whisper integration
- [ ] Replace MockTTSService with real Piper VITS integration
- [ ] Replace MockPronunciationService with real HuBERT integration
- [ ] Integrate Qwen2.5-1.5B + Unified LoRA adapter
- [ ] Integrate LLaMA3-8B-VI for Vietnamese explanations
- [ ] Integrate all-MiniLM-L6-v2 for context embeddings
- [ ] Setup Redis cache for learner profiles
- [ ] Integrate Knowledge Graph (NetworkX / KuzuDB)
- [ ] Add comprehensive unit tests
- [ ] Add integration tests
- [ ] Performance benchmarking
- [ ] Add monitoring and logging

## ğŸ“ Notes

**Current Status:**
- Complete architecture skeleton implemented
- All core interfaces defined
- Mock implementations for testing
- â³ Waiting for actual AI model integrations

**Mock Services:**
All services currently use mock implementations that simulate the behavior and latency of real models. These should be replaced with actual model integrations for production.

**Design Principles:**
- Hybrid Models: Qwen (English) + LLaMA3 (Vietnamese)
- Unified Adapter: 1 adapter for 4 tasks
- Lazy Loading: Load models only when needed
- Parallel Processing: Grammar + Pronunciation simultaneously
- Caching: Common responses, learner profiles
- Fallback: Graceful degradation on errors

## ğŸ”— Related Documentation

- [Architecture Document](/docs/architecture.md) - Full AI architecture v2.0
- [Phase 1 Completion](/docs/phase1_ui_completion.md) - UI implementation status
- [Tasks](/docs/tasks.md) - Development tasks and timeline

---

**Author:** Nguyen Huu Thang  
**Version:** 1.0  
**Last Updated:** January 2026
