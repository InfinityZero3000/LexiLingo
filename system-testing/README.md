# LexiLingo System Testing Tools

Bá»™ cÃ´ng cá»¥ kiá»ƒm thá»­ Ä‘á»™c láº­p Ä‘á»ƒ test cÃ¡c há»‡ thá»‘ng AI cá»§a LexiLingo.

## ğŸ“¦ Danh sÃ¡ch cÃ´ng cá»¥

### 1. **Dual-Stream Tester** (`dual-stream-tester.html`)
Kiá»ƒm thá»­ real-time streaming STT/TTS vá»›i WebSocket.

**TÃ­nh nÄƒng:**
- âœ… WebSocket connection management
- âœ… Real-time audio recording & streaming
- âœ… STT partial & final transcripts
- âœ… TTS audio playback
- âœ… Interruption handling test
- âœ… Latency monitoring
- âœ… Message log viewer

**CÃ¡ch dÃ¹ng:**
1. Má»Ÿ file `dual-stream-tester.html` trong trÃ¬nh duyá»‡t
2. Äáº£m báº£o AI service Ä‘ang cháº¡y á»Ÿ `localhost:8001`
3. Click **Connect** Ä‘á»ƒ káº¿t ná»‘i WebSocket
4. Click **Start Recording** Ä‘á»ƒ báº¯t Ä‘áº§u thu Ã¢m
5. NÃ³i vÃ o microphone Ä‘á»ƒ test STT
6. Xem responses trong message log

**Test cases:**
- NÃ³i liÃªn tá»¥c Ä‘á»ƒ test streaming STT
- Ngáº¯t giá»¯a chá»«ng Ä‘á»ƒ test interruption handling
- Kiá»ƒm tra latency (target: <200ms first audio output)

---

### 2. **GraphCAG Tester** (`graphcag-tester.html`)
Kiá»ƒm thá»­ Knowledge Graph, Cache, vÃ  LangGraph workflows.

**TÃ­nh nÄƒng:**
- ğŸ§  **GraphCAG Pipeline**: Test full AI analysis pipeline
- ğŸ—ºï¸ **Knowledge Graph**: Query concepts, relationships, learning paths
- ğŸ’¾ **Cache Testing**: Test Redis cache operations (get/set/delete)
- ğŸ”„ **LangGraph Flow**: Test workflow orchestration & node execution

**CÃ¡ch dÃ¹ng:**

#### Tab 1: GraphCAG Pipeline
1. Nháº­p student input (vÃ­ dá»¥: "I go to school yesterday")
2. Chá»n topic vÃ  difficulty level
3. Click **Run GraphCAG Pipeline**
4. Xem káº¿t quáº£ analysis vá»›i feedback

#### Tab 2: Knowledge Graph
1. Chá»n query type:
   - **Get Concept**: Láº¥y thÃ´ng tin 1 concept
   - **Get Related**: TÃ¬m concepts liÃªn quan
   - **Get Examples**: Láº¥y vÃ­ dá»¥ vá» concept
   - **Find Learning Path**: TÃ¬m learning path
2. Nháº­p concept name (vÃ­ dá»¥: `present_simple`, `past_tense`)
3. Click **Query Knowledge Graph**

#### Tab 3: Cache Testing
1. Nháº­p cache key (vÃ­ dá»¥: `test_query_001`)
2. Nháº­p JSON value Ä‘á»ƒ cache
3. Set TTL (time to live in seconds)
4. Test cÃ¡c operations:
   - **Set Cache**: LÆ°u vÃ o Redis
   - **Get Cache**: Láº¥y ra tá»« Redis
   - **Delete**: XÃ³a key

#### Tab 4: LangGraph Flow
1. Chá»n workflow type:
   - **Analyze**: PhÃ¢n tÃ­ch student input
   - **Diagnose**: Cháº©n Ä‘oÃ¡n lá»—i
   - **Feedback**: Generate feedback
   - **Full Pipeline**: Cháº¡y toÃ n bá»™ flow
2. Nháº­p student input vÃ  context
3. Click **Execute Workflow**
4. Xem node execution timeline

---

## ğŸš€ Khá»Ÿi Ä‘á»™ng Backend

TrÆ°á»›c khi dÃ¹ng test tools, cáº§n cháº¡y AI service:

```bash
cd /path/to/LexiLingo/ai-service

# Activate Python environment
source /path/to/venv/bin/activate

# Set environment variables
export GEMINI_API_KEY='your-api-key'

# Run AI service
python -m uvicorn api.main_lite:app --host 0.0.0.0 --port 8001 --reload
```

Kiá»ƒm tra service Ä‘Ã£ cháº¡y:
```bash
curl http://localhost:8001/health
```

---

## ğŸ“Š Performance Targets

### Dual-Stream
| Metric | Target | Notes |
|--------|--------|-------|
| First audio output | <200ms | TTS streaming starts before full response |
| Interruption response | <100ms | VAD detection + TTS stop |
| Context switch | <50ms | Thinking pause/resume |

### GraphCAG
| Metric | Target | Notes |
|--------|--------|-------|
| Cache hit latency | <10ms | Redis lookup |
| Cache miss latency | <50ms | KG query + LLM generation |
| KG query time | <30ms | KuzuDB cypher query |
| Full pipeline | <500ms | End-to-end analysis |

---

## ğŸ§ª Test Scenarios

### Scenario 1: Streaming Conversation
**Dual-Stream Tester**

1. Connect to WebSocket
2. Start recording
3. Say: "Hello, can you help me with English grammar?"
4. Wait for AI response (audio should start playing)
5. Interrupt mid-response by speaking again
6. Check logs for interruption handling

**Expected:**
- Partial transcripts appear during speaking
- Final transcript appears when paused
- AI starts thinking immediately
- Audio plays back smoothly
- Interruption stops audio and starts new transcript

---

### Scenario 2: Knowledge Graph Query
**GraphCAG Tester â†’ Knowledge Graph Tab**

1. Query type: **Get Concept**
2. Concept name: `present_simple`
3. Click Query

**Expected:**
```json
{
  "concept": "present_simple",
  "definition": "Used for habits, facts, and general truths",
  "examples": [
    "I go to school every day",
    "She likes coffee"
  ],
  "related_concepts": ["present_continuous", "habits", "daily_routines"]
}
```

---

### Scenario 3: Cache Performance
**GraphCAG Tester â†’ Cache Tab**

1. Set cache with key `grammar_query_present_simple`
2. Get cache multiple times
3. Check metrics for hit rate

**Expected:**
- First SET: ~5-10ms
- Subsequent GETs: <2ms (Redis is fast!)
- Cache metrics update correctly

---

### Scenario 4: Full Pipeline
**GraphCAG Tester â†’ GraphCAG Pipeline Tab**

1. Input: "He go to the store yesterday"
2. Topic: "English Grammar - Past Tense"
3. Difficulty: Intermediate
4. Run pipeline

**Expected:**
```json
{
  "analysis": {
    "errors": [
      {
        "type": "verb_form",
        "incorrect": "go",
        "correct": "went",
        "explanation": "Past tense requires irregular verb form"
      }
    ]
  },
  "feedback": "Good try! Remember that 'go' changes to 'went' in past tense...",
  "examples": ["I went to school", "She went home"],
  "cache_hit": false,
  "latency_ms": 450
}
```

---

## ğŸ› Troubleshooting

### WebSocket connection failed
**Problem:** Cannot connect to `ws://localhost:8001`

**Solutions:**
1. Check AI service is running: `curl http://localhost:8001/health`
2. Check WebSocket endpoint exists: Look for `/ws/conversation/stream` in `ai-service/api/routes/websocket_stream.py`
3. Check CORS settings in `main_lite.py`

---

### Microphone access denied
**Problem:** Browser blocks microphone access

**Solutions:**
1. Use **HTTPS** (required for mic in Chrome)
2. Or use `localhost` (allowed for testing)
3. Check browser permissions: `chrome://settings/content/microphone`

---

### Cache operations fail
**Problem:** Redis connection error

**Solutions:**
1. Check Redis is running: `redis-cli ping`
2. Start Redis: `redis-server`
3. Check connection string in AI service config

---

### GraphCAG API returns 404
**Problem:** Endpoints not found

**Solutions:**
1. Check API routes are registered in `main_lite.py`
2. Look at available endpoints: `http://localhost:8001/docs`
3. Verify endpoint paths match those in test tool

---

## ğŸ“ Adding Custom Tests

### Example: Test new workflow node

1. Open `graphcag-tester.html`
2. Add new workflow type in `<select id="workflowType">`:
```html
<option value="my_custom_node">My Custom Node</option>
```

3. Backend must implement endpoint:
```python
@router.post("/ai/workflow/my_custom_node")
async def my_custom_node(request: WorkflowRequest):
    # Your implementation
    return {"result": "..."}
```

---

## ğŸ“š API Reference

### Dual-Stream WebSocket

**Endpoint:** `ws://localhost:8001/ws/conversation/stream?session_id=xxx&user_id=xxx`

**Client â†’ Server:**
- Binary audio chunks (PCM 16kHz mono, webm format)

**Server â†’ Client:**

| Message Type | Description | Example |
|--------------|-------------|---------|
| `connected` | Connection established | `{"type": "connected", "session_id": "..."}` |
| `transcript_partial` | Intermediate STT | `{"type": "transcript_partial", "text": "Hello"}` |
| `transcript_final` | Complete utterance | `{"type": "transcript_final", "text": "Hello there"}` |
| `thinking_start` | AI started processing | `{"type": "thinking_start"}` |
| `thinking_stop` | AI stopped | `{"type": "thinking_stop", "reason": "interrupted"}` |
| `response_text` | Tutor text | `{"type": "response_text", "text": "..."}` |
| `response_audio_start` | Audio stream begins | `{"type": "response_audio_start"}` |
| Binary | Audio chunks | WAV format audio data |
| `response_audio_end` | Audio complete | `{"type": "response_audio_end"}` |
| `error` | Error occurred | `{"type": "error", "message": "..."}` |

---

### GraphCAG REST API

**Base URL:** `http://localhost:8001`

#### 1. Analyze Student Input
```http
POST /ai/analyze
Content-Type: application/json

{
  "text": "I go to school yesterday",
  "topic": "Past Tense",
  "difficulty": "intermediate",
  "user_id": "user123",
  "session_id": "session456"
}
```

#### 2. Knowledge Graph Query
```http
POST /ai/kg/concept
Content-Type: application/json

{
  "concept": "present_simple",
  "depth": 2
}
```

#### 3. Cache Operations
```http
# Set cache
POST /ai/cache/set
{
  "key": "test_key",
  "value": {"data": "..."},
  "ttl": 3600
}

# Get cache
GET /ai/cache/get?key=test_key

# Delete cache
DELETE /ai/cache/delete?key=test_key
```

#### 4. LangGraph Workflow
```http
POST /ai/workflow/analyze
Content-Type: application/json

{
  "input": "He go to school",
  "context": {
    "topic": "present_tense",
    "level": "beginner"
  }
}
```

---

## ğŸ¯ Next Steps

1. **Open test tools** in browser
2. **Start AI service** (`uvicorn api.main_lite:app --port 8001`)
3. **Run test scenarios** following examples above
4. **Monitor performance** via stats dashboard
5. **Report issues** if latencies exceed targets

---

## ğŸ“ Support

**Issues:** Create issue in LexiLingo GitHub repo  
**Docs:** Check `/docs` folder for architecture details  
**API Docs:** Visit `http://localhost:8001/docs` when service is running

---

> **Version:** 1.0  
> **Last Updated:** 2026-02-03  
> **Author:** LexiLingo AI Team
