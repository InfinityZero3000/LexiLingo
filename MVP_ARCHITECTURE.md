# ğŸ¯ LexiLingo MVP Architecture (Simplified)

> **Optimized for rapid deployment, cost-effectiveness, and scalability**

---

## ğŸ“Š Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT LAYER                            â”‚
â”‚  (Flutter App - Mobile/Web/Desktop)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Backend Service â”‚                  â”‚  AI Service    â”‚
    â”‚   (Port 8000)   â”‚                  â”‚  (Port 8001)   â”‚
    â”‚                 â”‚                  â”‚                â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚ â”‚ PostgreSQL  â”‚ â”‚                  â”‚ â”‚  MongoDB   â”‚ â”‚
    â”‚ â”‚ (Users,     â”‚ â”‚                  â”‚ â”‚ (Sessions, â”‚ â”‚
    â”‚ â”‚  Courses,   â”‚ â”‚                  â”‚ â”‚  AI Data)  â”‚ â”‚
    â”‚ â”‚  Progress)  â”‚ â”‚                  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                  â”‚                â”‚
    â”‚                 â”‚                  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚ FastAPI         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚   Redis    â”‚ â”‚
    â”‚ JWT Auth        â”‚   Shared Auth    â”‚ â”‚  (Cache)   â”‚ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                         â”‚                â”‚
                                         â”‚ AI PIPELINE:   â”‚
                                         â”‚                â”‚
                                         â”‚ 1. STT â”€â”€â”€â”€â”€â”€â” â”‚
                                         â”‚    Whisper   â”‚ â”‚
                                         â”‚    244MB     â”‚ â”‚
                                         â”‚              â”‚ â”‚
                                         â”‚ 2. NLP â—„â”€â”€â”€â”€â”€â”¤ â”‚
                                         â”‚    Qwen      â”‚ â”‚
                                         â”‚    900MB(Q4) â”‚ â”‚
                                         â”‚              â”‚ â”‚
                                         â”‚ 3. KG â—„â”€â”€â”€â”€â”€â”€â”¤ â”‚
                                         â”‚    NetworkX  â”‚ â”‚
                                         â”‚    50MB      â”‚ â”‚
                                         â”‚              â”‚ â”‚
                                         â”‚ 4. TTS â—„â”€â”€â”€â”€â”€â”˜ â”‚
                                         â”‚    Piper     â”‚ â”‚
                                         â”‚    63MB      â”‚ â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ Memory Footprint

### Total Memory: **2.4GB** (fits in 4GB server)

| Component | Size (Disk) | RAM (Loaded) | When Loaded |
|-----------|-------------|--------------|-------------|
| **Faster-Whisper v3** | 244MB | 500MB | On voice input |
| **Qwen2.5-1.5B-Q4** | 900MB | 1200MB | Always |
| **Piper TTS** | 63MB | 200MB | On response gen |
| **Knowledge Graph** | 50MB | 100MB | Always |
| **Redis Cache** | - | 200MB | Always |
| **CAG Pre-generated** | 100MB | 100MB | On-demand |
| **Python Runtime** | - | 1000MB | Always |
| **TOTAL (Peak)** | ~1.4GB | ~3.3GB | Worst case |
| **TOTAL (Normal)** | ~1.4GB | ~2.6GB | Typical |
| **TOTAL (Baseline)** | ~1.4GB | ~1.6GB | Text-only |

**Optimization:** Lazy loading â†’ 1.6GB baseline

---

## âš¡ Performance Targets

### Latency Breakdown (per request)

```
Voice Input Flow:
â”œâ”€â”€ User speaks (2s)
â”œâ”€â”€ STT transcription: 50ms
â”œâ”€â”€ Context lookup (Redis): 10ms
â”œâ”€â”€ Qwen inference: 200ms
â”œâ”€â”€ KG query: 5ms
â”œâ”€â”€ TTS generation: 150ms
â””â”€â”€ Total: 415ms â†’ User hears response in <0.5s âœ…

Text Input Flow:
â”œâ”€â”€ User types
â”œâ”€â”€ Context lookup: 10ms
â”œâ”€â”€ Qwen inference: 200ms
â”œâ”€â”€ KG query: 5ms
â””â”€â”€ Total: 215ms â†’ Fast response âœ…
```

**Target:** <500ms total latency (excellent UX)

---

## ğŸ—ï¸ Technology Stack (Simplified)

### AI Components (No fine-tuning where not needed)

```yaml
Speech:
  STT: 
    - Model: Faster-Whisper v3 Base
    - Size: 244MB
    - Fine-tuned: âŒ No (pre-trained is good enough)
    - Accuracy: 95%+ on clear English
  
  TTS:
    - Model: Piper VITS (en_US-lessac-medium)
    - Size: 63MB
    - Fine-tuned: âŒ No (natural voice out-of-box)
    - Quality: Near-human

NLP:
  Core:
    - Model: Qwen2.5-1.5B-Instruct
    - Quantization: Q4_K_M (4-bit)
    - Fine-tuned: âœ… Yes (4 LoRA adapters)
      - Grammar correction
      - Vocabulary classification
      - Fluency scoring
      - Dialogue generation
    - Size: 900MB (down from 3GB)
    - Accuracy: 98% of float16

Knowledge:
  Graph:
    - Library: NetworkX (Python)
    - Nodes: 15K (words, rules, concepts)
    - Edges: 30K (relationships)
    - Size: 50MB in-memory
    - Query: <5ms (hashtable)
  
  CAG:
    - Pre-generated: 1000 lessons, 5000 exercises
    - Size: 100MB
    - Generation: Background async
  
  Cache:
    - Redis: 200MB
    - Hit rate: 40-50%
    - TTL: 7 days

Fallbacks (Cloud APIs):
  Vietnamese:
    - Primary: Google Translate API (free tier)
    - Backup: Gemini API
  
  Pronunciation:
    - Azure Speech API (free tier: 5hrs/mo)
    - Google Cloud Speech
```

---

## ğŸ’° Cost Breakdown

### Monthly Operating Costs

| Item | Details | Cost/mo |
|------|---------|---------|
| **Server (Railway)** | 4GB RAM, 2 vCPU | $20 |
| **PostgreSQL** | Included in server | $0 |
| **MongoDB** | Included in server | $0 |
| **Redis** | Included in server | $0 |
| **Google Translate API** | 500K chars free/mo | $0-5 |
| **Azure Speech** | 5hrs free/mo | $0-5 |
| **Domain + SSL** | Cloudflare (free) | $0 |
| **CDN** | Cloudflare (free) | $0 |
| **TOTAL MVP** | | **$20-30** |

**Scale costs (if 1000+ users):**
- Upgrade to 8GB server: +$28/mo
- Cloud APIs: +$20-50/mo
- Total: $68-108/mo (still affordable)

---

## ğŸ“ˆ Comparison: Full vs Simplified

| Metric | Full Architecture | **Simplified (MVP)** | Savings |
|--------|-------------------|----------------------|---------|
| Memory | 8.5GB | **2.4GB** | **72%** â†“ |
| Server | $48-150/mo | **$20-30/mo** | **75%** â†“ |
| Setup Time | 2-3 months | **3-4 weeks** | **60%** â†“ |
| Latency | 350ms | 500ms | 43% â†‘ (acceptable) |
| Quality | 100% | 95% | 5% â†“ (acceptable) |
| Offline | Partial | No | Trade-off |

**Winner:** Simplified for MVP! ğŸ†

---

## ğŸš€ Deployment Strategy

### Phase 1: MVP (Weeks 1-8)

```bash
Week 1-2: Infrastructure
â”œâ”€â”€ Setup Railway/DigitalOcean
â”œâ”€â”€ Deploy PostgreSQL + MongoDB + Redis
â”œâ”€â”€ Configure Docker Compose
â””â”€â”€ CI/CD with GitHub Actions

Week 3-4: Core AI
â”œâ”€â”€ Deploy Qwen quantized model
â”œâ”€â”€ Integrate Faster-Whisper
â”œâ”€â”€ Integrate Piper TTS
â””â”€â”€ Test end-to-end pipeline

Week 5-6: Knowledge Layer
â”œâ”€â”€ Build Knowledge Graph
â”œâ”€â”€ Implement CAG
â”œâ”€â”€ Setup Redis caching
â””â”€â”€ Cloud API fallbacks

Week 7-8: Integration & Polish
â”œâ”€â”€ Flutter app integration
â”œâ”€â”€ Performance tuning
â”œâ”€â”€ Load testing
â””â”€â”€ MVP Launch! ğŸ‰
```

### Phase 2: Scale (Months 3-6, if needed)

```bash
Add when >1000 users:
â”œâ”€â”€ 8GB server upgrade
â”œâ”€â”€ Add LLaMA3-VI (if Vietnamese critical)
â”œâ”€â”€ Add HuBERT (if pronunciation critical)
â”œâ”€â”€ Load balancer (handle 500+ concurrent)
â””â”€â”€ Monitoring (Prometheus + Grafana)
```

---

## ğŸ¯ Why This Architecture Works

### âœ… Advantages

1. **Cost-Effective**
   - $20-30/mo total for MVP
   - No expensive GPU needed
   - Free tier APIs for fallbacks

2. **Fast Deployment**
   - No complex model training needed (STT/TTS)
   - Only fine-tune core NLP
   - Standard Docker deployment

3. **Good Performance**
   - <500ms latency (excellent UX)
   - 95%+ accuracy (production-ready)
   - Handles 50-100 concurrent users

4. **Scalable**
   - Easy to upgrade server
   - Can add components later
   - Horizontal scaling possible

5. **Maintainable**
   - Simple architecture
   - Well-documented components
   - Standard tech stack

### âš ï¸ Trade-offs (Acceptable for MVP)

1. **No Offline Mode**
   - Needs internet connection
   - Mitigated: Cache common responses

2. **Higher Latency than Full**
   - 500ms vs 350ms
   - Still feels instant (<1s)

3. **API Dependency**
   - Vietnamese translation
   - Pronunciation analysis
   - Mitigated: Free tiers sufficient

4. **Limited Concurrency**
   - 50-100 users initially
   - Upgrade path clear

---

## ğŸ”’ Security Considerations

```yaml
Authentication:
  - JWT tokens (shared secret)
  - Password hashing (bcrypt)
  - Rate limiting (10 req/min/user)

Data Protection:
  - HTTPS only
  - Database encryption at rest
  - Redis password protected
  - No sensitive data in logs

API Security:
  - API keys in environment variables
  - Rotate keys monthly
  - Monitor usage

Privacy:
  - User data consent
  - GDPR compliance ready
  - Data deletion on request
```

---

## ğŸ“Š Monitoring & Metrics

```yaml
Track:
  Performance:
    - Latency (p50, p95, p99)
    - Throughput (req/sec)
    - Error rate

  Resources:
    - CPU usage
    - Memory usage
    - Disk usage
    - Network I/O

  Business:
    - Active users
    - Sessions/day
    - API costs
    - Cache hit rate

Tools:
  - Prometheus (metrics)
  - Grafana (dashboards)
  - Sentry (error tracking)
  - Railway logs
```

---

## âœ… Final Verdict

**Architecture Ä‘Æ¡n giáº£n hÃ³a nÃ y:**

```
âœ… HoÃ n toÃ n kháº£ thi cho production MVP
âœ… Cost-effective ($20-30/mo)
âœ… Fast deployment (6-8 weeks)
âœ… Good performance (<500ms)
âœ… Scalable khi cáº§n

Recommended: YES! ğŸ¯
```

**Next steps:**
1. Setup server infrastructure
2. Deploy quantized Qwen model
3. Integrate STT/TTS
4. Build KG + CAG
5. Launch MVP! ğŸš€

---

**Document version:** 1.0  
**Last updated:** 2026-01-24  
**Author:** LexiLingo Team

