# ğŸ‰ Hybrid Deployment Setup - Complete!

ÄÃ£ táº¡o xong complete hybrid deployment setup cho LexiLingo!

---

## ğŸ“ Files Ä‘Ã£ táº¡o

### ğŸ“š Documentation
- âœ… `docs/HYBRID_DEPLOYMENT_GUIDE.md` - HÆ°á»›ng dáº«n chi tiáº¿t (5000+ words)
- âœ… `docs/DEPLOYMENT_CHECKLIST.md` - Checklist tá»«ng bÆ°á»›c
- âœ… `docs/QUICK_START_HYBRID.md` - Quick start 30 phÃºt

### âš™ï¸ Configuration Files
- âœ… `backend-service/render.yaml` - Render.com config
- âœ… `flutter-app/vercel.json` - Vercel config
- âœ… `web-admin/netlify.toml` - Netlify config
- âœ… `docker-compose.local.yml` - Docker cho local AI

### ğŸ”§ Scripts
- âœ… `scripts/start-ai-local.sh` - Start AI + tunnel
- âœ… `scripts/stop-ai-local.sh` - Stop services
- âœ… `scripts/deploy-hybrid.sh` - Guided deployment
- âœ… `scripts/setup-launchd.sh` - Auto-start setup
- âœ… `scripts/com.lexilingo.ai.local.plist` - macOS LaunchAgent

---

## ğŸš€ Báº¯t Ä‘áº§u deploy ngay

### CÃ¡ch 1: Quick Start (30 phÃºt)
```bash
# 1. Start AI service vá»›i tunnel
bash scripts/start-ai-local.sh

# 2. Follow guided deployment
bash scripts/deploy-hybrid.sh

# Done! ğŸ‰
```

### CÃ¡ch 2: Äá»c hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§
```bash
# Má»Ÿ hÆ°á»›ng dáº«n chi tiáº¿t
open docs/HYBRID_DEPLOYMENT_GUIDE.md

# Hoáº·c checklist
open docs/DEPLOYMENT_CHECKLIST.md
```

---

## ğŸ’¡ Kiáº¿n trÃºc Hybrid

```
â˜ï¸ CLOUD (FREE)                    ğŸ  YOUR MACHINE ($0)
â”œâ”€ Frontend (Vercel)               â””â”€ AI Service (localhost:8001)
â”œâ”€ Admin (Netlify)                     â”‚
â”œâ”€ Backend (Render.com)                â”œâ”€ Whisper STT (244MB)
â”‚   â””â”€ Database (Supabase)             â”œâ”€ Qwen NLP (900MB)
â”‚                                      â”œâ”€ Piper TTS (63MB)
â””â”€ Connected via â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â””â”€ Knowledge Graph
        Cloudflare Tunnel (Free!)
```

---

## ğŸ’° Chi phÃ­

| Component | Monthly Cost |
|-----------|-------------|
| All Cloud Services | $0 |
| Local AI (Ä‘iá»‡n) | ~$6 |
| **TOTAL** | **$6/month** |

**So sÃ¡nh:** Full cloud AI = $50-100/month  
**Tiáº¿t kiá»‡m:** **$44-94/month** ğŸ‰

---

## âœ… TÃ­nh nÄƒng

âœ… **HoÃ n toÃ n miá»…n phÃ­** (chá»‰ tráº£ Ä‘iá»‡n cho AI local)  
âœ… **No cold start** cho AI (always on trÃªn mÃ¡y báº¡n)  
âœ… **Full GPU power** (dÃ¹ng GPU cá»§a mÃ¡y local)  
âœ… **Auto-restart** khi mÃ¡y boot  
âœ… **Public access** qua Cloudflare Tunnel  
âœ… **SSL/TLS** automatic  
âœ… **DDoS protection** built-in  
âœ… **Monitoring ready** (uptime checks)

---

## ğŸ“Š Platform Details

### Frontend - Vercel
- âœ… Unlimited bandwidth
- âœ… Global CDN
- âœ… Auto SSL
- âœ… Deploy on git push

### Admin - Netlify  
- âœ… 100GB bandwidth/month
- âœ… Forms & serverless functions
- âœ… Instant rollbacks

### Backend - Render.com
- âœ… 750 hours/month free
- âš ï¸ Sleep sau 15 phÃºt (cold start 30s)
- ğŸ’¡ DÃ¹ng uptime monitor Ä‘á»ƒ keep alive

### Database - Supabase
- âœ… 500MB storage
- âœ… Realtime subscriptions  
- âœ… Built-in auth
- âœ… Auto backups

### AI Service - Local
- âœ… No limits!
- âœ… Full control
- âœ… Your hardware
- ğŸ’¡ Expose via Cloudflare Tunnel

---

## ğŸ”§ Next Steps

### 1. Test Scripts Locally
```bash
# Test AI service start
bash scripts/start-ai-local.sh

# Check output - should show tunnel URL
# Example: https://abc-123.trycloudflare.com
```

### 2. Prepare Environment
```bash
# Copy env example
cp ai-service/.env.example ai-service/.env

# Edit vÃ  thÃªm:
# - GEMINI_API_KEY (get from https://makersuite.google.com/app/apikey)
nano ai-service/.env
```

### 3. Deploy to Cloud
```bash
bash scripts/deploy-hybrid.sh
```

Script sáº½ guide báº¡n qua:
- â˜ï¸ Supabase database setup
- ğŸš€ Render.com backend deploy
- ğŸ¨ Vercel frontend deploy
- ğŸ“Š Netlify admin deploy
- ğŸ”— Connect everything together

### 4. Setup Auto-start (Optional)
```bash
bash scripts/setup-launchd.sh
```

---

## ğŸ“ Important Files to Edit

TrÆ°á»›c khi deploy, cáº§n update:

### 1. `ai-service/.env`
```env
GEMINI_API_KEY=your_actual_key_here
```

### 2. `backend-service/firebase-service-account.json`
- Äáº£m báº£o file nÃ y cÃ³ credentials Ä‘Ãºng

### 3. Update URLs sau khi deploy:
- Backend: `render.yaml` hoáº·c Render dashboard
- Frontend: Environment variables trong Vercel
- Admin: Environment variables trong Netlify

---

## ğŸ“ Learning Resources

### Video Tutorials (Recommended)
1. **Render.com**: https://www.youtube.com/watch?v=bnCOyGaSe84
2. **Vercel Flutter**: https://www.youtube.com/watch?v=Dd8W8KsPU4g
3. **Cloudflare Tunnel**: https://www.youtube.com/watch?v=ZvIdFs3M5ic

### Official Docs
- [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/)
- [Render](https://render.com/docs)
- [Vercel](https://vercel.com/docs)
- [Netlify](https://docs.netlify.com)
- [Supabase](https://supabase.com/docs)

---

## ğŸ†˜ Troubleshooting

### Issue: Cloudflared not found
```bash
# macOS
brew install cloudflare/cloudflare/cloudflared

# Ubuntu/Debian
wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
sudo dpkg -i cloudflared-linux-amd64.deb
```

### Issue: AI service won't start
```bash
# Check virtual environment
source .venv/bin/activate
pip install -r ai-service/requirements.txt

# Check port
lsof -ti:8001  # If occupied, kill it
```

### Issue: Tunnel URL changes after restart
```bash
# Normal behavior - tunnel URL is temporary
# Solutions:
# 1. Use permanent tunnel (need Cloudflare account - still free)
# 2. Update URL in Render/Vercel/Netlify when changed
# 3. Use systemd/launchd to keep same tunnel alive
```

---

## ğŸ’» System Requirements

### Your Machine (for AI Service)
- **OS:** macOS / Linux / Windows (WSL)
- **RAM:** 4GB+ free (8GB recommended)
- **Storage:** 2GB for models
- **Network:** Stable internet for tunnel
- **Optional:** GPU for faster processing

### Development
- Python 3.11+
- Flutter 3.24+
- Node.js 20+
- Git

---

## ğŸ¯ Performance Expectations

### Latency
- **Text-only chat:** ~200-300ms
- **Voice input:** ~500-800ms (STT + NLP)
- **TTS response:** ~1-2s total
- **Backend API:** ~50-100ms (Render)
- **Tunnel overhead:** ~20-50ms

### Throughput
- **Concurrent users:** 5-10 with local AI
- **Scale:** Add cloud AI when >10 concurrent

### Uptime
- **Cloud services:** 99.9% (platform SLA)
- **Local AI:** Depends on your machine uptime
- **Tunnel:** 99.9% (Cloudflare)

---

## ğŸ‰ Success Criteria

Sau khi deploy xong, báº¡n nÃªn cÃ³:

âœ… Frontend accessible táº¡i `https://[app].vercel.app`  
âœ… Admin accessible táº¡i `https://[admin].netlify.app`  
âœ… Backend API táº¡i `https://[api].onrender.com`  
âœ… AI Service exposed táº¡i `https://[tunnel].trycloudflare.com`  
âœ… Database running trÃªn Supabase  
âœ… ToÃ n bá»™ services connected vÃ  functional  
âœ… Cost: $0/month (chá»‰ tráº£ Ä‘iá»‡n) ğŸŠ

---

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á»:

1. **Check logs:**
   ```bash
   tail -f logs/ai-local.log
   tail -f logs/tunnel.log
   ```

2. **Verify services:**
   ```bash
   curl http://localhost:8001/health  # AI local
   curl https://[tunnel]/health       # AI public
   curl https://[backend]/health      # Backend
   ```

3. **Read docs:**
   - [HYBRID_DEPLOYMENT_GUIDE.md](./docs/HYBRID_DEPLOYMENT_GUIDE.md)
   - [DEPLOYMENT_CHECKLIST.md](./docs/DEPLOYMENT_CHECKLIST.md)

4. **Open GitHub issue** vá»›i full error logs

---

## ğŸš¦ Status

- âœ… Documentation complete
- âœ… Config files ready
- âœ… Scripts executable
- âœ… Ready to deploy!

**Next action:** Run `bash scripts/start-ai-local.sh` ğŸš€

---

*Generated by GitHub Copilot - Hybrid Deployment Setup*  
*Date: February 7, 2026*
