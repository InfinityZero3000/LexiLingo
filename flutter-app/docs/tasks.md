# K·∫ø Ho·∫°ch Tri·ªÉn Khai Module AI Chat - LexiLingo v2.0

> **T√†i li·ªáu**: Danh s√°ch nhi·ªám v·ª• chi ti·∫øt ƒë·ªÉ hi·ªán th·ª±c h√≥a ki·∫øn tr√∫c AI Chat  
> **Ki·∫øn tr√∫c**: Clean Architecture + Modular Feature-First  
> **Core Engine**: Flutter App (Phase 1) ‚Üí Python AI Orchestrator (Phase 2)  
> **Tr·∫°ng th√°i**: ‚¨ú Ch∆∞a b·∫Øt ƒë·∫ßu | Ho√†n th√†nh | üöß ƒêang th·ª±c hi·ªán  
> **Last Updated**: January 15, 2026

---

## üìä T·ªïng Quan Ti·∫øn ƒê·ªô

### ƒê√£ Ho√†n Th√†nh
- **Chat Feature c∆° b·∫£n v·ªõi Google Gemini AI**
  - Clean Architecture implementation
  - Domain Layer: Entities, Repositories, UseCases
  - Data Layer: Models, DataSources (Remote + Local Web)
  - Presentation Layer: ChatProvider, ChatPage UI
  - API Key security v·ªõi flutter_dotenv
  - Web storage v·ªõi SharedPreferences

### üöß ƒêang Th·ª±c Hi·ªán
- Testing v√† t·ªëi ∆∞u Chat UI
- Voice input/output integration

### üìã K·∫ø Ho·∫°ch Ti·∫øp Theo
- Advanced AI features (Pronunciation, Grammar analysis)
- Python AI Orchestrator backend
- LoRA fine-tuning cho specialized tasks

---

## Phase 0: Flutter Chat MVP (Current Implementation) ‚úÖ

**M·ª•c ti√™u**: X√¢y d·ª±ng chat feature c∆° b·∫£n v·ªõi Google Gemini AI, cho ph√©p user chat v√† nh·∫≠n feedback

### 0.1 Infrastructure Setup ‚úÖ
- [x] **Environment Configuration**
    - [x] Setup flutter_dotenv cho API key management
    - [x] T·∫°o .env file v·ªõi GEMINI_API_KEY v√† HF_API_KEY
    - [x] Gitignore .env ƒë·ªÉ b·∫£o m·∫≠t API keys
    - [x] Configure Firebase cho authentication
- [x] **Dependency Injection (GetIt)** 
    - [x] Setup injection_container.dart
    - [x] Register SharedPreferences cho web platform
    - [x] Conditional registration (skipDatabase cho web)

### 0.2 Domain Layer ‚úÖ
- [x] **Entities**
    - [x] `ChatMessage`: id, sessionId, content, role, timestamp, status
    - [x] `ChatSession`: id, userId, title, createdAt, lastMessageAt
    - [x] Enums: MessageRole, MessageStatus, AIModel
- [x] **Repositories (Abstract)**
    - [x] `ChatRepository`: interface v·ªõi methods sendMessage, getAIResponse, createSession, getSessions, getMessages
- [x] **UseCases**
    - [x] `CreateSessionUseCase`: T·∫°o chat session m·ªõi
    - [x] `GetSessionsUseCase`: L·∫•y danh s√°ch sessions
    - [x] `GetChatHistoryUseCase`: L·∫•y l·ªãch s·ª≠ chat c·ªßa session
    - [x] `SendMessageUseCase`: G·ª≠i message v√† nh·∫≠n AI response

### 0.3 Data Layer ‚úÖ
- [x] **Models**
    - [x] `ChatMessageModel`: extends Entity, c√≥ fromJson/toJson, toMap/fromMap
    - [x] `ChatSessionModel`: extends Entity, c√≥ fromJson/toJson, toMap/fromMap
- [x] **Data Sources**
    - [x] `ChatRemoteDataSource`: Integration v·ªõi Google Gemini API
        - [x] Method sendMessage(String message)
        - [x] Method getAIResponse v·ªõi conversation history support
        - [x] Error handling v√† exceptions
    - [x] `ChatLocalDataSource`: Abstract interface cho local storage
        - [x] SQLite implementation cho mobile (`ChatLocalDataSourceImpl`)
        - [x] SharedPreferences implementation cho web (`ChatLocalDataSourceWeb`)
    - [x] `NetworkInfo`: Interface v√† implementation ƒë·ªÉ check network status
- [x] **Repositories (Implementation)**
    - [x] `ChatRepositoryImpl`: 
        - [x] K·∫øt h·ª£p local + remote data sources
        - [x] Network check logic
        - [x] Error handling v·ªõi Either<Failure, T> pattern
        - [x] Conversation context management

### 0.4 Presentation Layer ‚úÖ
- [x] **State Management**
    - [x] `ChatProvider`: Qu·∫£n l√Ω chat state v·ªõi ChangeNotifier
        - [x] Sessions list management
        - [x] Messages list management
        - [x] Loading states
        - [x] Error handling
        - [x] Send message flow
        - [x] Create session flow
- [x] **UI Components**
    - [x] `ChatPage`: Main chat screen
    - [x] Basic message display
    - [x] Input field v√† send button
    - [x] Session management UI

### 0.5 Integration & Deployment ‚úÖ
- [x] **Dependency Registration**
    - [x] Register t·∫•t c·∫£ dependencies trong injection_container
    - [x] Platform-specific implementations (web vs mobile)
- [x] **Provider Setup**
    - [x] Add ChatProvider v√†o MultiProvider trong main.dart
- [x] **Web Testing**
    - [x] Test app tr√™n Chrome
    - [x] Verify API connection v·ªõi Gemini
    - [x] Test SharedPreferences storage

---

## Phase 1: Chat UI Enhancement & Voice Features üöß

**M·ª•c ti√™u**: C·∫£i thi·ªán UI/UX v√† th√™m voice input/output

### 1.1 UI Improvements ‚úÖ
- [x] **Enhanced Chat Interface**
    - [x] `MessageBubble`: Widget v·ªõi styling cho User vs AI messages
    - [x] Avatar icons cho User v√† AI
    - [x] Timestamp display cho m·ªói message
    - [x] Markdown rendering cho AI responses
    - [x] Copy message content feature
    - [x] Message status indicators (sending, sent, error)
- [x] **Session Management UI**
    - [x] Session list sidebar/drawer
    - [x] Create new session button
    - [x] Delete session action (UI ready, backend pending)
    - [x] Rename session dialog (UI ready, backend pending)
    - [ ] Search sessions
- [ ] **Responsive Design**
    - [ ] Mobile layout optimization
    - [ ] Tablet layout
    - [ ] Desktop layout v·ªõi sidebar
    - [ ] Dark mode support (partial - colors implemented)

### 1.2 Voice Input (Basic STT)
- [ ] **Audio Recording**
    - [ ] `AudioRecorderButton`: Widget v·ªõi recording animation
    - [ ] Permission handling (microphone)
    - [ ] Audio file recording v√† storage
- [ ] **Speech-to-Text Integration**
    - [ ] Integrate v·ªõi Google Cloud Speech-to-Text API (ho·∫∑c Web Speech API cho web)
    - [ ] Display transcribed text in input field
    - [ ] Error handling cho STT failures

### 1.3 Voice Output (Basic TTS)
- [ ] **Text-to-Speech**
    - [ ] Play button tr√™n AI messages
    - [ ] Integrate v·ªõi Flutter TTS package
    - [ ] Playback controls (pause, stop)
    - [ ] Audio streaming cho long responses

---

## Phase 2: Advanced AI Features & Analysis

**M·ª•c ti√™u**: Th√™m grammar correction, pronunciation analysis, v√† feedback chi ti·∫øt

### 2.1 Grammar & Fluency Analysis
- [ ] **Enhanced AI Prompting**
    - [ ] Update system prompts ƒë·ªÉ request structured feedback
    - [ ] Parse JSON response t·ª´ Gemini v·ªõi grammar errors
    - [ ] Display grammar corrections trong UI
- [ ] **Feedback Widget**
    - [ ] `FeedbackCard`: Widget hi·ªÉn th·ªã analysis results
    - [ ] Grammar error highlights
    - [ ] Fluency score visualization
    - [ ] Vocabulary level indicator
    - [ ] Suggestions panel

### 2.2 Pronunciation Analysis (Future)
- [ ] **Pronunciation Model Integration**
    - [ ] Research pronunciation analysis APIs
    - [ ] Integrate v·ªõi pronunciation service
    - [ ] Phoneme comparison logic
- [ ] **Pronunciation Feedback UI**
    - [ ] `PronunciationView`: Popup v·ªõi phoneme-level feedback
    - [ ] Visual waveform display
    - [ ] Highlight incorrect phonemes
    - [ ] Play reference audio
    - [ ] Practice mode

### 2.3 Knowledge Graph & RAG System
- [ ] **Knowledge Graph Construction**
    - [ ] Design schema cho nodes: Vocab (Word), Grammar (Rule), Topic (Concept)
    - [ ] Design relationships: "is_a", "related_to", "prerequisite_of", "difficulty_level"
    - [ ] Select technology: NetworkX (lightweight) vs KuzuDB (production-ready)
    - [ ] Create base vocabulary graph (CEFR A2-B2 ~3000 words)
    - [ ] Create grammar rules graph (~100 common rules)
    - [ ] Create topic/concept graph (daily life, work, travel, etc.)
- [ ] **Graph Population**
    - [ ] Script ƒë·ªÉ import vocabulary t·ª´ CEFR wordlists
    - [ ] Parse grammar rules t·ª´ textbooks/resources
    - [ ] Build relationships automatically (word frequency, co-occurrence)
    - [ ] Add metadata: difficulty_level, example_sentences, usage_frequency
- [ ] **Graph RAG Integration**
    - [ ] Query engine cho semantic search
    - [ ] Context retrieval based on user level
    - [ ] Related concepts suggestion
    - [ ] Prerequisite checking for curriculum planning
- [ ] **Curriculum Planning System**
    - [ ] Use graph ƒë·ªÉ suggest next learning topics
    - [ ] Adaptive difficulty based on user progress
    - [ ] Spaced repetition scheduling v·ªõi graph metadata

### 2.4 Progress Tracking
- [ ] **Learning Analytics**
    - [ ] Track user mistakes over time
    - [ ] Common error patterns
    - [ ] Progress visualization (charts)
    - [ ] Vocabulary growth tracking
- [ ] **Personalization**
    - [ ] User level detection (A2, B1, B2)
    - [ ] Adaptive difficulty
    - [ ] Personalized recommendations

---

## Phase 3: Python AI Orchestrator Backend (Future Enhancement)

**M·ª•c ti√™u**: X√¢y d·ª±ng backend AI chuy√™n bi·ªát v·ªõi LoRA fine-tuning

### 3.0 MongoDB Integration for AI Learning Loop ‚úÖ

**Completed**: January 15, 2026

- [x] **MongoDB Setup**
  - [x] Create `docker-compose.yml` v·ªõi MongoDB + Redis + Mongo Express
  - [x] Create `scripts/mongo-init.js` v·ªõi collections & indexes
  - [x] Create `config/mongodb_config.yaml` v·ªõi dev/prod environments
  - [x] Environment-aware configuration (Local Docker vs Atlas)
  
- [x] **MongoDB Client Implementation**
  - [x] `model/mongodb_client.py`: Singleton client v·ªõi auto-detection
  - [x] Methods: log_interaction, get_user_interactions, log_model_metrics
  - [x] Connection pooling v√† retry logic
  - [x] TTL indexes cho auto-cleanup (90 days)
  
- [x] **Logging Middleware**
  - [x] `model/logging_middleware.py`: Automatic logging decorator
  - [x] MetricsCollector cho performance tracking
  - [x] Non-blocking async logging
  
- [x] **Collections Schema**
  - [x] ai_interactions: Full interaction logs + feedback loop
  - [x] model_metrics: Performance tracking over time
  - [x] learning_patterns: Aggregated user error patterns
  - [x] training_queue: Curated examples for LoRA fine-tuning
  
- [x] **Documentation**
  - [x] `docs/MONGODB_ATLAS_SETUP.md`: Step-by-step Atlas setup
  - [x] `docs/MONGODB_SCHEMA.md`: Collections schema reference
  - [x] Update `architecture.md` with MongoDB layer

**Usage**:
```bash
# Start local MongoDB
cd DL-Model-Support
docker-compose up -d

# Test connection
python model/mongodb_client.py

# Access Mongo Express UI
open http://localhost:8081
```

### 3.1 M√¥i Tr∆∞·ªùng & Dataset Chu·∫©n B·ªã

### 3.1 M√¥i Tr∆∞·ªùng & Dataset Chu·∫©n B·ªã
- [ ] **Setup Python Environment**
    - [ ] T·∫°o Virtual Environment (`venv` ho·∫∑c `conda`) v·ªõi Python 3.10+
    - [ ] C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán core: `torch`, `transformers`, `peft`, `bitsandbytes`, `huggingface_hub`
    - [ ] C√†i ƒë·∫∑t th∆∞ vi·ªán x·ª≠ l√Ω audio: `librosa`, `soundfile`, `faster-whisper`
    - [ ] C√†i ƒë·∫∑t th∆∞ vi·ªán graph: `networkx`, `kuzu` (ho·∫∑c `neo4j`)
    - [ ] C√†i ƒë·∫∑t server framework: `fastapi`, `uvicorn`, `redis`
    - [ ] C√†i ƒë·∫∑t NLP utilities: `sentence-transformers`, `spacy`
    - [ ] T·∫°o file `requirements.txt` c·∫≠p nh·∫≠t ƒë·∫ßy ƒë·ªß version
- [ ] **Model Selection & Download**
    - [ ] **STT**: Download Whisper-small (244MB) via faster-whisper
      ```python
      # Recommended: Whisper-small (WER <10% for ESL)
      from faster_whisper import WhisperModel
      model = WhisperModel("small", device="cpu", compute_type="int8")
      # Alternative: "medium" (769MB, WER <7%) n·∫øu c·∫ßn accuracy cao h∆°n
      ```
    - [ ] **NLP**: Download Qwen2.5-1.5B-Instruct (~1.5GB)
      ```python
      # Recommended cho MVP: Balance speed/quality
      from transformers import AutoModelForCausalLM
      model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-1.5B-Instruct")
      # Alternative: Qwen2.5-3B-Instruct (3GB) n·∫øu c√≥ GPU m·∫°nh
      ```
    - [ ] **Vietnamese**: Download LLaMA3-8B-VI (8GB) v·ªõi 4-bit quantization
    - [ ] **Context Encoder**: Download all-MiniLM-L6-v2 (22MB)
    - [ ] **Pronunciation**: Download HuBERT-large (960MB) - optional cho phase sau
- [ ] **Dataset Collection & Processing**
    - [ ] T·∫£i EFCAMDAT dataset (Fluency scoring)
    - [ ] T·∫£i BEA-2019 / CoNLL-2014 dataset (Grammar correction)
    - [ ] T·∫£i AutoTutor Dialogue Corpus (Pedagogical strategy)
    - [ ] T·∫£i Oxford Graded Readers / CEFR corpus (Vocabulary leveling)
    - [ ] Download CEFR vocabulary lists (A2, B1, B2) - ~3000 words
    - [ ] Download grammar rule collections (Cambridge, Oxford)
    - [ ] Vi·∫øt script `processing/data_cleaner.py` ƒë·ªÉ chu·∫©n h√≥a ƒë·ªãnh d·∫°ng d·ªØ li·ªáu v·ªÅ JSONL instruction format
    - [ ] Chia split Train/Validation/Test (80/10/10)
- [ ] **Knowledge Graph Initial Data**
    - [ ] Prepare vocabulary nodes CSV (word, level, pos, definition, examples)
    - [ ] Prepare grammar nodes CSV (rule_id, name, level, description, examples)
    - [ ] Prepare topic nodes CSV (topic_id, name, related_vocab, related_grammar)
    - [ ] Prepare relationships CSV (source, target, relationship_type, weight)

### 3.2 Model Base & Fine-tuning (LoRA)
- [ ] **Qwen2.5-1.5B Base Setup**
    - [ ] T·∫£i model `Qwen/Qwen2.5-1.5B-Instruct`
    - [ ] Vi·∫øt script l∆∞·ª£ng t·ª≠ h√≥a (Quantization) v·ªÅ 4-bit (BNB4) ƒë·ªÉ ti·∫øt ki·ªám RAM
- [ ] **Unified Adapter Training**
    - [ ] C·∫•u h√¨nh LoRA config (rank=48, alpha=96, modules=[all linear])
    - [ ] Vi·∫øt training script `train_unified.py` s·ª≠ d·ª•ng th∆∞ vi·ªán `peft`
    - [ ] ƒê·ªãnh nghƒ©a Prompt Template cho Multi-tasking (Fluency, Grammar, Vocab, Dialogue)
    - [ ] Train Unified Adapter tr√™n dataset t·ªïng h·ª£p (~16.7k samples)
    - [ ] Export Adapter (`adapter_model.bin`) v√† `adapter_config.json`
- [ ] **Model Evaluation**
    - [ ] Vi·∫øt script `eval_fluency.py` (T√≠nh MAE, Pearson correlation)
    - [ ] Vi·∫øt script `eval_grammar.py` (T√≠nh F0.5 score, Precision/Recall)
    - [ ] Ch·∫°y benchmark so s√°nh performance v·ªõi baseline

### 3.3 Audio Models Setup
- [ ] **STT Module (Whisper)**
    - [ ] Setup `faster-whisper` v·ªõi model `small` ho·∫∑c `distil-small.en`
    - [ ] T·ªëi ∆∞u h√≥a v·ªõi CTranslate2 ƒë·ªÉ ch·∫°y tr√™n CPU/Mobile
    - [ ] Implement VAD (Voice Activity Detection) v·ªõi Silero VAD ƒë·ªÉ l·ªçc kho·∫£ng l·∫∑ng
- [ ] **Pronunciation Module (HuBERT)**
    - [ ] T·∫£i model `facebook/hubert-large-ls960`
    - [ ] Implement thu·∫≠t to√°n DTW (Dynamic Time Warping) ƒë·ªÉ so kh·ªõp phoneme
    - [ ] X√¢y d·ª±ng h√†m t√≠nh ƒëi·ªÉm ph√°t √¢m (Phone-level accuracy map)
- [ ] **TTS Module (Piper)**
    - [ ] Compile Piper TTS engine
    - [ ] T·∫£i voice model `en_US-lessac-medium`
    - [ ] Test latency sinh audio

---

---

    - [ ] Implement conversation embedding aggregation
- [ ] **Knowledge Graph Manager**
    - [ ] Class `KnowledgeGraphManager` ƒë·ªÉ qu·∫£n l√Ω graph
    - [ ] Load graph v√†o memory (NetworkX) ho·∫∑c connect to DB (KuzuDB)
    - [ ] Method `query_related_concepts(word, max_depth=2)` ƒë·ªÉ RAG
    - [ ] Method `get_prerequisites(topic)` cho curriculum planning
    - [ ] Method `suggest_next_topics(user_progress, current_level)`
    - [ ] Cache frequently accessed subgraphs trong Redis
- [ ] **Resource Manager**
    - [ ] Implement Singleton Pattern cho Model Loading
    - [ ] X√¢y d·ª±ng c∆° ch·∫ø Lazy Loading cho LLaMA3-VI (ch·ªâ load khi c·∫ßn ti·∫øng Vi·ªát)
    - [ ] X√¢y d·ª±ng c∆° ch·∫ø Offloading (chuy·ªÉn model t·ª´ GPU v·ªÅ CPU khi RAM ƒë·∫ßy)
    - [ ] Memory monitoring v√† auto-cleanup
### 4.1 Core Components Implementation
- [ ] **Context Manager**
    - [ ] S·ª≠ d·ª•ng `all-MiniLM-L6-v2` ƒë·ªÉ encode ng·ªØ c·∫£nh h·ªôi tho·∫°i
    - [ ] X√¢y d·ª±ng Sliding Window Buffer (gi·ªØ context c·ªßa 5 turn g·∫ßn nh·∫•t)
    - [ ] T√≠ch h·ª£p Redis ƒë·ªÉ l∆∞u/ƒë·ªçc `user_level`, `learning_history`
    - [ ] Integrate v·ªõi Knowledge Graph ƒë·ªÉ query related concepts
    - [ ] Complexity assessment based on vocabulary level
- [ ] **Pipeline Execution**
    - [ ] X√¢y d·ª±ng class `AIOrchestrator` ch√≠nh
    - [ ] Implement `async` flow ƒë·ªÉ ch·∫°y song song Qwen v√† HuBERT
    - [ ] Implement Knowledge Graph RAG trong pipeline
    - [ ] X√¢y d·ª±ng c∆° ch·∫ø Error Handling & Fallback (nh∆∞ thi·∫øt k·∫ø trong architecture.md)
    - [ ] Implement logic Fusion & Aggregation ƒë·ªÉ g·ªôp k·∫øt qu·∫£ t·ª´ c√°c model
- [ ] **Feedback Strategy Engine**
    - [ ] Implement 4 strategies: PRAISE, CORRECT, EXPLAIN, DRILL
    - [ ] Level adaptation logic (A2/B1/B2)
    - [ ] Response length controller
    - [ ] Vietnamese hint generator (conditional)
### 2.2 Orchestrator Logic
- [ ] **Task Analyzer**
    - [ ] Vi·∫øt logic ph√¢n t√≠ch intent ng∆∞·ªùi d√πng (H·ªèi ng·ªØ ph√°p? Chat vu v∆°? Luy·ªán t·∫≠p?)
    - [ ] Logic x√°c ƒë·ªãnh chi·∫øn l∆∞·ª£c d·∫°y (Socratic, Scaffolding, Feedback) d·ª±a tr√™n l·ªãch s·ª≠ l·ªói
    - [ ] Request model: message, session_id, user_level, context
    - [ ] Response model: analysis, response_en, response_vi, scores, next_action
- [ ] Thi·∫øt k·∫ø API Endpoint: `POST /v1/audio/transcriptions` (STT)
- [ ] Thi·∫øt k·∫ø API Endpoint: `POST /v1/audio/speech` (TTS)
- [ ] Thi·∫øt k·∫ø API Endpoint: `GET /v1/knowledge/concepts/{concept_id}`
    - [ ] Query related concepts t·ª´ Knowledge Graph
- [ ] Thi·∫øt k·∫ø API Endpoint: `GET /v1/curriculum/suggest`
    - [ ] Suggest next topics based on user progress
- [ ] Middleware: Rate limiting, Authentication, Logging Request/Response
- [ ] WebSocket support cho streaming responses
    - [ ] X√¢y d·ª±ng c∆° ch·∫ø Error Handling & Fallback (nh∆∞ thi·∫øt k·∫ø trong architecture.md)
    4 [ ] Implement logic Fusion & Aggregation ƒë·ªÉ g·ªôp k·∫øt qu·∫£ t·ª´ c√°c model

### 2.3 API Gateway (FastAPI)
- [ ] Thi·∫øt k·∫ø API Endpoint: `POST /v1/chat/completions`
- [ ] Thi·∫øt k·∫ø API Endpoint: `POST /v1/audio/transcriptions` (STT)
- [ ] Thi·∫øt k·∫ø API Endpoint: `POST /v1/audio/speech` (TTS)
- [ ] Middleware: Rate limiting, Authentication, Logging Request/Response

---

## Phase 5: Backend Integration v·ªõi Flutter App

**M·ª•c ti√™u**: Migrate t·ª´ Gemini API sang custom AI Orchestrator backend

### 5.1 Backend API Client
- [ ] **API Client Implementation**
    - [ ] T·∫°o `OrchestratorAPIClient` class
    - [ ] Implement endpoints: `/v1/chat/completions`, `/v1/audio/transcriptions`, `/v1/audio/speech`
    - [ ] Authentication v√† headers
- [ ] **Knowledge Graph Features**
    - [ ] Vocabulary level indicator cho t·ª´ng message
    - [ ] Related concepts suggestion panel
    - [ ] Learning path visualization
    - [ ] Prerequisite checker tr∆∞·ªõc khi h·ªçc topic m·ªõi

---

## Phase 7: Knowledge Graph & Curriculum System (Future)

**M·ª•c ti√™u**: X√¢y d·ª±ng h·ªá th·ªëng Knowledge Graph v√† curriculum planning th√¥ng minh

### 7.1 Knowledge Graph Development
- [ ] **Graph Schema Design**
    - [ ] Design node types: VocabNode, GrammarNode, TopicNode, LevelNode
    - [ ] Design edge types v√† properties
    - [ ] Define metadata schema
- [ ] **Graph Database Setup**
    - [ ] Choose between NetworkX (simple) v√† KuzuDB/Neo4j (scalable)
    - [ ] Setup database connection
    - [ ] Create indexes cho fast queries
- [ ] **Data Population Pipeline**
    - [ ] Import CEFR vocabulary (~3000 words)
    - [ ] Import grammar rules (~100 rules)
    - [ ] Import topics v√† concepts
    - [ ] Build relationships automatically
    - [ ] Validate graph consistency

### 7.2 RAG Integration
- [ ] **Semantic Search**
    - [ ] Implement vector similarity search trong graph
    - [ ] Context-aware concept retrieval
    - [ ] Multi-hop reasoning (traverse graph)
- [ ] **Query Optimization**
    - [ ] Cache frequent queries
    - [ ] Optimize graph traversal algorithms
    - [ ] Batch queries cho performance

### 7.3 Curriculum Planning
- [ ] **Adaptive Learning Path**
    - [ ] Algorithm ƒë·ªÉ suggest next topics
    - [ ] Difficulty progression based on user level
    - [ ] Prerequisite checking
    - [ ] Spaced repetition scheduling
- [ ] **Progress Tracking**
    - [ ] Track mastered concepts trong graph
    - [ ] Update edge weights based on user performance
    - [ ] Generate learning reports
- [ ] **Personalization**
    - [ ] Build user knowledge graph (subgraph of main graph)
    - [ ] Identify knowledge gaps
    - [ ] Recommend targeted practice
    - [ ] Request/Response models cho Orchestrator API
- [ ] **Data Source Updates**
    - [ ] Update `ChatRemoteDataSource` ƒë·ªÉ support c·∫£ Gemini v√† Orchestrator
    - [ ] Feature flag ƒë·ªÉ switch gi·ªØa 2 backends
    - [ ] Graceful fallback n·∫øu Orchestrator unavailable

### 5.2 Advanced Features Integration
- [ ] **Analysis Results**
    - [ ] Parse structured response t·ª´ Orchestrator (fluency, grammar, vocab)
    - [ ] Update ChatMessage entity ƒë·ªÉ l∆∞u analysis data
    - [ ] Display detailed feedback trong UI
- [ ] **Pronunciation Data**
    - [ ] Receive pronunciation analysis t·ª´ backend
    - [ ] Store audio files v√† phoneme data
    - [ ] Render pronunciation feedback UI
    - [ ] `AudioRecorderButton`: N√∫t ghi √¢m v·ªõi animation s√≥ng
    - [ ] `PronunciationView`: Popup hi·ªÉn th·ªã chi ti·∫øt l·ªói ph√°t √¢m (t√¥ ƒë·ªè phoneme sai)

---

## Phase 4: Testing & Optimization

### 4.1 Unit Testing
- [ ] **Backend Tests (`pytest`)**
   

### Phase 7: Knowledge Graph & Curriculum ‚¨ú (0%)
```
‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
``` - [ ] Test Orchestrator logic (Mock model outputs)
    - [ ] Test LoRA Adapter outputs (Input sample -> Output structure check)
    - [ ] Test API endpoints (Input validation, Response format)
- [ ] **Mobile Tests (`flutter_test`)**
    - [ ] Test Domain UseCases
---

## Phase 6: Testing & Optimization

### 6
### 4.2 Integration Testing
- [ ] Test flow tr·ªçn v·∫πn: User Voice Input -> STT -> Orchestrator -> Response -> TTS -> Mobile Audio Playback
- [ ] Ki·ªÉm tra ƒë·ªô tr·ªÖ (Latency) to√†n tr√¨nh. Target: < 2s cho c√¢u tr·∫£ l·ªùi ƒë·∫ßu ti√™n.

### 4.3 Deployment
- [ ] ƒê√≥ng g√≥i Docker cho AI Backend Service
- [ ] Setup CI/CD Pipeline (GitHub Actions)
- [ ] Build Flutter App (release mode) cho Android/iOS

---6

## Checklists Theo D√µi

### 6.3 Performance Optimization
- [ ] **Mobile Optimization**
    - [ ] Optimize image loading v√† caching
    - [ ] Lazy loading 

### Sprint 4 (Future) - Knowledge Graph Foundation
- [ ] Design Knowledge Graph schema
- [ ] Collect and prepare graph data (vocabulary, grammar, topics)
- [ ] Setup graph database (NetworkX/KuzuDB)
- [ ] Implement basic RAG queries
- [ ] Build curriculum suggestion APIcho message history
    - [ ] Memory leak detection
    - [ ] Battery usage optimization
- [ ] **Network Optimization**
---

## üìä Progress Dashboard

### Phase 0: Flutter Chat MVP (100%)
```
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
```
- Domain Layer: Complete

4. **Knowledge Graph Technology**:
   - üéØ MVP: NetworkX (Python, lightweight, in-memory)
     - Easy to prototype
     - Fast for small graphs (<10k nodes)
     - ‚ö†Ô∏è Limited scalability
   - üìã Production: KuzuDB ho·∫∑c Neo4j
     - Optimized for graph queries
     - Persistent storage
     - Better performance at scale

5. **RAG Strategy**:
   - Hybrid approach: Vector similarity + Graph traversal
   - Use sentence embeddings (MiniLM) cho semantic search
   - Use graph edges cho prerequisite/related concept queries
- Data Layer: Complete  
- Presentation Layer: Complete
- Integration: Complete

### Phase 1: Chat UI Enhancement üöß (70%)
```
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 70%
```
- UI Improvements: Complete (90% - search sessions pending)
- Voice Input: ‚¨ú Not Started
- Voice Output: ‚¨ú Not Started

### Phase 2: Advanced AI Features ‚¨ú (0%)
```
‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
```

### Phase 3-6: Backend & Integration ‚¨ú (0%)
```
‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
```

---

## üéØ Current Sprint Goals

### Sprint 1 (Current) - Chat MVP Completion ‚úÖ
- [x] Setup secure API key management
- [x] Implement Clean Architecture cho Chat feature
- [x] Create basic Chat UI
- [x] Test Gemini AI integration
- [x] Deploy to web (Chrome testing)

### Sprint 2 (Next) - UI Enhancement ‚úÖ
- [x] Improve message bubble styling
- [x] Add session management UI
- [x] Implement markdown rendering
- [ ] Add dark mode support (partial)
- [ ] Mobile responsive design
- [ ] Voice features integration (moved to Sprint 3)

### Sprint 3 (Future) - Voice Features
- [ ] Integrate Speech-to-Text
- [ ] Knowledge Graph not built yet (needed for advanced features)

### Performance Metrics (Target)
- Initial load: < 2s
- Message send to response: < 3s (Gemini) / < 2s (Orchestrator)
- UI responsiveness: 60 FPS
- Memory usage: < 150MB (mobile)
- Knowledge Graph query: < 5ms (cached) / < 50ms (cold)
- RAG retrieval: < 100ms

### Data Requirements
- Vocabulary: ~3000 words (CEFR A2-B2)
- Grammar rules: ~100 common rules
- Topics: ~50 conversation topics
- Example sentences: ~10k sentences
- Graph edges: ~15k relationships
## üìù Notes & Decisions

### Technical Decisions
1. **API Choice**: Started v·ªõi Google Gemini API cho MVP speed
   - Pros: Quick setup, no training needed, good quality
   - ‚ö†Ô∏è Cons: Vendor lock-in, limited customization
   - üìã Plan: Migrate to custom Orchestrator khi c·∫ßn specialized features

2. **Model Selection**:
   - **STT (Speech-to-Text)**: Whisper-small (medium-whisper)
     - 244MB, WER <10% for ESL learners
     - Excellent Vietnamese accent support
     - Word-level timestamps cho pronunciation analysis
     - üìã Upgrade to "medium" (769MB) n·∫øu c·∫ßn WER <7%
   
   - **NLP**: Qwen2.5-1.5B-Instruct
     - 1.5GB, latency 100-150ms
     - Sufficient cho grammar/fluency/vocab tasks
     - Can run on 8GB RAM laptop
     - üìã Consider 3B version (3GB, +5-10% accuracy) khi c√≥ GPU server

3. **Storage Strategy**: 
   - Mobile: SQLite via DatabaseHelper
   - Web: SharedPreferences
   - üìã Future: Sync v·ªõi Firebase/Firestore

4. **State Management**: Provider pattern
   - Simple, official, suitable cho app size
   - üìã Consider Riverpod khi app grows

### Known Issues
- [ ] Chat page session list not implemented yet
- [ ] No error retry mechanism in UI
- [ ] Missing loading indicators for long responses

### Performance Metrics (Target)
- Initial load: < 2s
- Message send to response: < 3s (Gemini)
- UI responsiveness: 60 FPS
- Memory usage: < 150MB (mobile)

---

**Last Updated**: January 15, 2026  
**Next Review**: After Sprint 2 completion  
**Ghi ch√∫**: Lu√¥n c·∫≠p nh·∫≠t file n√†y sau m·ªói sprint/milestone ho√†n th√†nh

---
**Ghi ch√∫**: Th·ª±c hi·ªán tu·∫ßn t·ª± theo c√°c Phase. Lu√¥n c·∫≠p nh·∫≠t tr·∫°ng th√°i v√†o file n√†y sau m·ªói phi√™n l√†m vi·ªác.
